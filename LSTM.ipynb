{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "978ba30c-4572-40c9-8ef7-908b7ebb3abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "raw = pd.read_csv('TX_2021_monthly.csv')\n",
    "#raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebbd0d08-e0b9-4fb3-9549-848e3e6ebde5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of data points: 3048\n",
      "number of counties: 254\n"
     ]
    }
   ],
   "source": [
    "# number of data points\n",
    "print('number of data points:', raw.shape[0])\n",
    "# number of counties\n",
    "print('number of counties:', raw['county'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69131cf5-380d-4cab-b98d-99711b4a20c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace 'Suppressed' with 5\n",
    "raw['annual_all_deaths'] = raw['annual_all_deaths'].replace('Suppressed', 5)\n",
    "raw['annual_hospital_deaths'] = raw['annual_hospital_deaths'].replace('Suppressed', 5)\n",
    "raw['monthly_hospital_deaths'] = raw['monthly_hospital_deaths'].replace('Suppressed', 5)\n",
    "raw['monthly_covid_hospital_deaths'] = raw['monthly_covid_hospital_deaths'].replace('Suppressed', 5)\n",
    "#raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90dcf2bf-f048-48b7-93ec-424710e70e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert death number from string to integer\n",
    "#print('data type of each feature before converting:\\n',raw.dtypes)\n",
    "raw[['annual_all_deaths', 'annual_hospital_deaths', 'monthly_hospital_deaths', 'monthly_covid_hospital_deaths']] = raw[['annual_all_deaths', 'annual_hospital_deaths', 'monthly_hospital_deaths', 'monthly_covid_hospital_deaths']].astype(int)\n",
    "#print('data type of each feature after converting:\\n',raw.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3687ad91-0bbd-4d4c-9539-690109fb0bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the number of monthly hosptial death without covid\n",
    "raw['monthly_noncovid_hospital_deaths'] = raw['monthly_hospital_deaths'] - raw['monthly_covid_hospital_deaths']\n",
    "#raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00faedee-8d5c-4f55-8d95-2f415b36ef98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3048, 254)\n"
     ]
    }
   ],
   "source": [
    "# use onehot encoding to encode the feature 'county'\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "onehot = OneHotEncoder(sparse_output = False)\n",
    "county_encoded = onehot.fit_transform(raw[['county']])\n",
    "print(county_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06cbeda6-fa4e-4802-a0c8-d8b828eaf854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# given the name of a county, find its onehot vector representation\n",
    "def get_county_encoding(county_name):\n",
    "    county_list = raw['county'].tolist()\n",
    "    if county_name in county_list:\n",
    "        county_index = county_list.index(county_name)\n",
    "        county_encoding = county_encoded[county_index]\n",
    "        return county_encoding\n",
    "    else:\n",
    "        print('County not found.')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4495347-2163-4674-b4ff-4f2d25ceb4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the monthly_noncovid_hospital_deaths before feeding it into LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "raw['monthly_noncovid_hospital_deaths_scaled'] = scaler.fit_transform(raw[['monthly_noncovid_hospital_deaths']])\n",
    "#raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2c4c7ed-35fc-41e7-9ada-fa0263a1a4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the 'raw' data into training set (Jan to Nov) and testing set (Dec)\n",
    "raw_train = raw.loc[raw['month'] != 'Dec',:]\n",
    "raw_test = raw.loc[raw['month'].isin(['Sep', 'Oct', 'Nov', 'Dec']),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c1b9a3a-ed4a-42b1-b613-ee7800bb4aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "death_train.shape (2794, 1)\n",
      "death_test.shape (1016, 1)\n"
     ]
    }
   ],
   "source": [
    "# convert the 'monthly_noncovid_hospital_deaths_scaled' into [rows, columns] structure\n",
    "death_train = np.array(raw_train['monthly_noncovid_hospital_deaths_scaled'])\n",
    "death_train = death_train.reshape(len(death_train),1)\n",
    "print('death_train.shape', death_train.shape)\n",
    "death_test = np.array(raw_test['monthly_noncovid_hospital_deaths_scaled'])\n",
    "death_test = death_test.reshape(len(death_test),1)\n",
    "print('death_test.shape', death_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44db9455-6a20-48be-81d4-934316df362a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "county_train_encoded.shape: (2794, 254)\n",
      "county_test_encoded.shape: (1016, 254)\n"
     ]
    }
   ],
   "source": [
    "# create the county feature for training set and testing set\n",
    "county_train = raw_train['county']\n",
    "county_train_encoded = county_train.map(get_county_encoding)\n",
    "county_train_encoded = np.vstack(county_train_encoded)\n",
    "print('county_train_encoded.shape:', county_train_encoded.shape)\n",
    "county_test = raw_test['county']\n",
    "county_test_encoded = county_test.map(get_county_encoding)\n",
    "county_test_encoded = np.vstack(county_test_encoded)\n",
    "print('county_test_encoded.shape:', county_test_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf64fe2c-ca27-4477-840a-b0c785f4685c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_train.shape (2794, 255)\n",
      "data_test.shape (1016, 255)\n"
     ]
    }
   ],
   "source": [
    "# horizontally stack the county feature and the death feature\n",
    "data_train = np.hstack((county_train_encoded, death_train))\n",
    "print('data_train.shape', data_train.shape)\n",
    "data_test = np.hstack((county_test_encoded, death_test))\n",
    "print('data_test.shape', data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31850896-0f28-44d3-a700-5dbc79cc700f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a multivariate sequence into samples\n",
    "def split_sequence(sequence, n_timestep): # n_timestep is the window size\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        end_ix = i+ n_timestep # find the end of the pattern\n",
    "        if end_ix > len(sequence)-1: # check if we are beyond the dataset\n",
    "            break\n",
    "        seq_x = sequence[i:end_ix, :]\n",
    "        seq_y = sequence[end_ix, -1]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db1c3d97-668b-4878-a64c-e57fbab6bd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# given a two dimensional array of each county and death number, calcaute a sequence for each county and concatenate them together\n",
    "def get_input_sequence(array, n_timestep):\n",
    "    X_list, y_list = list(), list() #empty list to hold the sequence of each county\n",
    "    for i in range(raw['county'].nunique()):\n",
    "        n_obs_each_county = int(len(array)/raw['county'].nunique()) # number of observations for each county\n",
    "        begin_index = n_obs_each_county*i\n",
    "        end_index = begin_index + n_obs_each_county\n",
    "        subset_array = array[begin_index:end_index,] # split the array into each county to create sequence for each county\n",
    "        X_county, y_county = split_sequence(subset_array, n_timestep)\n",
    "        X_list.append(X_county)\n",
    "        y_list.append(y_county)\n",
    "    # vertically stack X_county\n",
    "    X = np.vstack(X_list)\n",
    "    # concatenate y_county\n",
    "    y = np.concatenate(y_list)\n",
    "    return X, y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f5beabc-0ca1-4870-b8ca-370042369d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (2032, 3, 255)\n",
      "y_train.shape: (2032,)\n",
      "X_test.shape: (254, 3, 255)\n",
      "y_test.shape: (254,)\n"
     ]
    }
   ],
   "source": [
    "#If X_train has shape (num_samples, n_timestep, n_features), \n",
    "#then X_test should also have shape (num_test_samples, n_timestep, n_features)**\n",
    "X_train, y_train = get_input_sequence(array = data_train, n_timestep = 3)\n",
    "print('X_train.shape:',X_train.shape)\n",
    "print('y_train.shape:',y_train.shape)\n",
    "X_test, y_test = get_input_sequence(array = data_test, n_timestep = 3)\n",
    "print('X_test.shape:', X_test.shape)\n",
    "print('y_test.shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7275dd37-9316-44e2-a695-77df8b0b70eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_timestep = X_train.shape[1]\n",
    "n_features = X_train.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "119abb9c-a4a7-474b-9b00-5e52cd763505",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "import tensorflow as tf\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27429ea7-b14d-407b-8659-ed84f1d762f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix the seed so that we can replicate the results\n",
    "random.seed(9999)\n",
    "np.random.seed(9999)\n",
    "tf.random.set_seed(9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d2c869e2-9f60-4712-99ec-06f8932a1f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a model with one LSTM layer and one dense layer\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(LSTM(50, activation = 'relu', input_shape = (n_timestep, n_features)))\n",
    "model_lstm.add(Dense(1,))\n",
    "model_lstm.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "822fc19a-ccdc-4cee-9d4a-551fc89b3c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 50)                61200     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 61251 (239.26 KB)\n",
      "Trainable params: 61251 (239.26 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "model_lstm.fit(X_train, y_train, epochs = 200, verbose = False)\n",
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0ae6fad7-52f6-429c-a52f-24399a529c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 705us/step - loss: 3.6057e-05\n",
      "mse_train: 3.605739402701147e-05\n",
      "8/8 [==============================] - 0s 894us/step - loss: 4.2491e-05\n",
      "mse_test: 4.249086123309098e-05\n"
     ]
    }
   ],
   "source": [
    "# calcuate the MSE for training set and testing set\n",
    "mse_train = model_lstm.evaluate(X_train, y_train)\n",
    "print('mse_train:', mse_train)\n",
    "mse_test = model_lstm.evaluate(X_test, y_test)\n",
    "print('mse_test:', mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "594f020c-aa9b-4efc-a04b-bf771ec06803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 1ms/step\n",
      "y_predicted.shape (254,)\n"
     ]
    }
   ],
   "source": [
    "# predict the death rate and convert it back to the orignal scaley\n",
    "y_predicted = model_lstm.predict(X_test)\n",
    "y_predicted = scaler.inverse_transform(y_predicted)\n",
    "y_predicted = y_predicted.reshape(y_predicted.shape[0])\n",
    "print('y_predicted.shape', y_predicted.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9c9e22e3-1fec-4f6c-bab2-783414e64290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_ture.shape (254,)\n"
     ]
    }
   ],
   "source": [
    "# extract the true value of the death number\n",
    "y_true = raw.loc[raw['month'] == 'Dec',:]['monthly_noncovid_hospital_deaths'].values\n",
    "print('y_ture.shape', y_true.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f101f9e5-6aaa-4729-8e02-34ccc81f3e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of the testing data at orignal scale = 97.14016770202026\n"
     ]
    }
   ],
   "source": [
    "# calculate the MSE at orignal scale\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse_test_original_scale = mean_squared_error(y_true, y_predicted)\n",
    "print('MSE of the testing data at orignal scale =', mse_test_original_scale)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
